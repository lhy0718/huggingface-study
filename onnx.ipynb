{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# loading pretrained tokenizer and text classification model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bhadresh-savani/bert-base-uncased-emotion')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# defining dummy input"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "dummy_input_texts = [\n",
    "    'My name is Clara and I live in Berkeley, California. I work at this cool company called Hugging Face.',\n",
    "    'Hello, my dog is cute.',\n",
    "    'This is bad.',\n",
    "    'I like you. I love you'\n",
    "]\n",
    "\n",
    "dummy_inputs = tokenizer(\n",
    "    dummy_input_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "print('\\n'.join([f'text{idx} -> {tokenizer.decode(text)}' for idx,\n",
    "      text in enumerate(dummy_inputs['input_ids'])]))\n",
    "\n",
    "# batch_size = len(dummy_input_texts)\n",
    "# dummy_inputs['labels'] = torch.full((1, batch_size), model.num_labels-1)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text0 -> [CLS] my name is clara and i live in berkeley, california. i work at this cool company called hugging face. [SEP]\n",
      "text1 -> [CLS] hello, my dog is cute. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "text2 -> [CLS] this is bad. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "text3 -> [CLS] i like you. i love you [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# feeding dummy input to PyTorch model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "outputs = model(**dummy_inputs)\n",
    "\n",
    "print('\\n'.join([f'text{idx} -> {model.config.id2label[int(logit.argmax())]}:\\\n",
    "      {float(logit.softmax(dim=-1).max())*100:.2f}%'\n",
    "      for idx, logit in enumerate(outputs.logits)]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text0 -> joy:      99.87%\n",
      "text1 -> joy:      99.79%\n",
      "text2 -> sadness:      72.95%\n",
      "text3 -> joy:      74.21%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# exporting PyTorch model to ONNX format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers.models.bert import BertOnnxConfig\n",
    "\n",
    "config = model.config\n",
    "onnx_config = BertOnnxConfig(config)\n",
    "\n",
    "input_names = list(onnx_config.inputs.keys())\n",
    "input_values = tuple([dummy_inputs[key] for key in input_names])\n",
    "output_names = list(outputs.keys())\n",
    "output_path = 'onnx/bert-base-uncased/bert-base-uncased-emotion.onnx'\n",
    "\n",
    "torch.onnx.export(model, input_values, output_path, input_names=input_names, output_names=output_names, opset_version=10)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# feeding dummy input to ONNX model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import onnxruntime as ort\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "ort_session = ort.InferenceSession(\"onnx/bert-base-uncased/bert-base-uncased-emotion.onnx\")\n",
    "\n",
    "inputs = tokenizer(dummy_input_texts, return_tensors=\"np\",\n",
    "                   padding=True, truncation=True)\n",
    "outputs = ort_session.run(output_names, dict(inputs))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# printing ONNX model's output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "print('\\n'.join([f'text{idx} -> {model.config.id2label[int(output.argmax())]}:\\\n",
    "      {float(torch.Tensor(output).softmax(dim=-1).max())*100:.2f}%'\n",
    "      for idx, output in enumerate(torch.Tensor(outputs)[0])]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text0 -> joy:      99.87%\n",
      "text1 -> joy:      99.79%\n",
      "text2 -> sadness:      72.95%\n",
      "text3 -> joy:      74.21%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('venv': conda)"
  },
  "interpreter": {
   "hash": "a4dfd762fc3f058fbb072f431cf34d4bd09d42457cf6569815d3bec7adc6bd52"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}